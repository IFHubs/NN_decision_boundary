{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib64/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import tflearn\n",
    "from utils import *\n",
    "from model_graph import densenet_mnist\n",
    "from itertools import cycle\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]='0'\n",
    "mnist_data = input_data.read_data_sets(\"MNIST_data\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inputs = tf.placeholder(tf.float32, [None, 28, 28, 1], name='inputs')\n",
    "targets = tf.placeholder(tf.float32, [None, 10], name='targets')\n",
    "input_shortcut = tf.placeholder(tf.float32, [None, 2], name='input_shortcut')\n",
    "train_flag = tf.placeholder(tf.bool, name='training')\n",
    "shortcut_flag = tf.placeholder(tf.bool, name='shortcut')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "output, feature_transform = densenet_mnist(inputs, 10, 40, 12, 1.0,\n",
    "                                     train_flag,shortcut_flag, input_shortcut)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#This part is for computing the accuracy of this model\n",
    "pred_y = tf.nn.softmax(output)\n",
    "pred_y_true = tf.argmax(pred_y, 1)\n",
    "y_true = tf.argmax(targets, 1)\n",
    "correct_prediction = tf.equal(pred_y_true, y_true)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "# loss function and optimizer\n",
    "cost = tf.reduce_mean((tf.nn.softmax_cross_entropy_with_logits(logits=output, labels=targets)))\n",
    "\n",
    "step_adam = tf.train.AdamOptimizer(1e-4).minimize(cost)\n",
    "step_momentum = tf.train.MomentumOptimizer(0.01, 0.9).minimize(cost)\n",
    "step_gd = tf.train.GradientDescentOptimizer(0.0001).minimize(cost)\n",
    "\n",
    "all_variables = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES)\n",
    "last_layer_variables = filter(lambda x: 'Variable' in x.name, all_variables)\n",
    "previous_layer_variables = filter(lambda x: 'Variable' not in x.name, all_variables)\n",
    "\n",
    "step_sgd_previous_layer = tf.train.GradientDescentOptimizer(0.0001).minimize(cost,\n",
    "                        var_list = previous_layer_variables)\n",
    "\n",
    "optimizer_sgd_last_layer = tf.train.GradientDescentOptimizer(1e-4)\n",
    "step_sgd_last_layer = optimizer_sgd_last_layer.minimize(cost,\n",
    "                        var_list = last_layer_variables)\n",
    "optimizer_m_last_layer = tf.train.MomentumOptimizer(1e-4, 0.9)\n",
    "step_m_last_layer = optimizer_m_last_layer.minimize(cost,\n",
    "                        var_list = last_layer_variables)\n",
    "\n",
    "\n",
    "# optimizer = tf.train.MomentumOptimizer(0.0001, 0.9).minimize(cost)\n",
    "saver = tf.train.Saver(tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES))\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.log_device_placement=False\n",
    "config.allow_soft_placement=True\n",
    "config.gpu_options.allow_growth=True\n",
    "session = tf.Session(config=config)\n",
    "session.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "def optimize(optimizer_step, epochs):\n",
    "\n",
    "    for i in (range(epochs)):\n",
    "        epoch_loss = []\n",
    "        start_epoch = time.time()\n",
    "        for ii in range(mnist_data.train.num_examples//batch_size):\n",
    "            batch = mnist_data.train.next_batch(batch_size)\n",
    "            imgs = batch[0].reshape((-1, 28, 28, 1))\n",
    "            labs = batch[1]\n",
    "\n",
    "            dict_input = {inputs:imgs, targets:labs, \n",
    "                          train_flag: True, \n",
    "                          shortcut_flag: False,\n",
    "                          input_shortcut: np.zeros([batch_size, 2])}\n",
    "\n",
    "            c, _ = session.run([cost, optimizer_step], feed_dict=dict_input)\n",
    "            epoch_loss.append(c)\n",
    "        print(\"Epoch: {}/{}\".format(i+1, epochs), \"| Training accuracy: \", session.run(accuracy, feed_dict=dict_input), \n",
    "              \"| Cost: {}\".format(np.mean(epoch_loss)), \" | Time for epoch: {:.2f}s\".format(time.time() - start_epoch))\n",
    "        if i%100==0:\n",
    "            saver.save(session,'../model/mnist_densenet_10_class_mom_{}.ckpt'.format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch: 1/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00193927530199', ' | Time for epoch: 81.26s')\n",
      "('Epoch: 2/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00245688809082', ' | Time for epoch: 82.91s')\n",
      "('Epoch: 3/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00256832246669', ' | Time for epoch: 84.50s')\n",
      "('Epoch: 4/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00218947185203', ' | Time for epoch: 85.36s')\n",
      "('Epoch: 5/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00215068482794', ' | Time for epoch: 84.81s')\n",
      "('Epoch: 6/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00218554935418', ' | Time for epoch: 83.90s')\n",
      "('Epoch: 7/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00231116404757', ' | Time for epoch: 85.01s')\n",
      "('Epoch: 8/1001', '| Training accuracy: ', 1.0, '| Cost: 0.0021285621915', ' | Time for epoch: 84.27s')\n",
      "('Epoch: 9/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00226741284132', ' | Time for epoch: 84.58s')\n",
      "('Epoch: 10/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00212611141615', ' | Time for epoch: 84.29s')\n",
      "('Epoch: 11/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00215123686939', ' | Time for epoch: 84.16s')\n",
      "('Epoch: 12/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00226359255612', ' | Time for epoch: 83.59s')\n",
      "('Epoch: 13/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00204454339109', ' | Time for epoch: 83.80s')\n",
      "('Epoch: 14/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00224959128536', ' | Time for epoch: 83.62s')\n",
      "('Epoch: 15/1001', '| Training accuracy: ', 1.0, '| Cost: 0.002106849337', ' | Time for epoch: 84.03s')\n",
      "('Epoch: 16/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00207378854975', ' | Time for epoch: 83.90s')\n",
      "('Epoch: 17/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00212911190465', ' | Time for epoch: 83.97s')\n",
      "('Epoch: 18/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00197914824821', ' | Time for epoch: 84.32s')\n",
      "('Epoch: 19/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00215015653521', ' | Time for epoch: 84.13s')\n",
      "('Epoch: 20/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00217263493687', ' | Time for epoch: 84.32s')\n",
      "('Epoch: 21/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00212860340253', ' | Time for epoch: 84.36s')\n",
      "('Epoch: 22/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00178262311965', ' | Time for epoch: 83.38s')\n",
      "('Epoch: 23/1001', '| Training accuracy: ', 1.0, '| Cost: 0.0017038830556', ' | Time for epoch: 84.20s')\n",
      "('Epoch: 24/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00209756568074', ' | Time for epoch: 83.52s')\n",
      "('Epoch: 25/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00200865487568', ' | Time for epoch: 83.95s')\n",
      "('Epoch: 26/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00161821430083', ' | Time for epoch: 83.91s')\n",
      "('Epoch: 27/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00185877503827', ' | Time for epoch: 83.93s')\n",
      "('Epoch: 28/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00176659110002', ' | Time for epoch: 83.92s')\n",
      "('Epoch: 29/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00679876748472', ' | Time for epoch: 84.33s')\n",
      "('Epoch: 30/1001', '| Training accuracy: ', 1.0, '| Cost: 0.0286315213889', ' | Time for epoch: 84.37s')\n",
      "('Epoch: 31/1001', '| Training accuracy: ', 1.0, '| Cost: 0.0112425666302', ' | Time for epoch: 84.10s')\n",
      "('Epoch: 32/1001', '| Training accuracy: ', 1.0, '| Cost: 0.0122182574123', ' | Time for epoch: 84.56s')\n",
      "('Epoch: 33/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00786304846406', ' | Time for epoch: 84.40s')\n",
      "('Epoch: 34/1001', '| Training accuracy: ', 0.99609375, '| Cost: 0.00967596657574', ' | Time for epoch: 83.94s')\n",
      "('Epoch: 35/1001', '| Training accuracy: ', 1.0, '| Cost: 0.015900997445', ' | Time for epoch: 83.61s')\n",
      "('Epoch: 36/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00606006616727', ' | Time for epoch: 83.75s')\n",
      "('Epoch: 37/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00460567884147', ' | Time for epoch: 83.48s')\n",
      "('Epoch: 38/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00268097128719', ' | Time for epoch: 83.91s')\n",
      "('Epoch: 39/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00239406223409', ' | Time for epoch: 84.00s')\n",
      "('Epoch: 40/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00227279495448', ' | Time for epoch: 83.64s')\n",
      "('Epoch: 41/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00240065483376', ' | Time for epoch: 84.03s')\n",
      "('Epoch: 42/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00243154820055', ' | Time for epoch: 84.12s')\n",
      "('Epoch: 43/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00169948884286', ' | Time for epoch: 84.11s')\n",
      "('Epoch: 44/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00198711431585', ' | Time for epoch: 83.98s')\n",
      "('Epoch: 45/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00232630735263', ' | Time for epoch: 83.82s')\n",
      "('Epoch: 46/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00180727057159', ' | Time for epoch: 84.10s')\n",
      "('Epoch: 47/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00200417567976', ' | Time for epoch: 84.31s')\n",
      "('Epoch: 48/1001', '| Training accuracy: ', 1.0, '| Cost: 0.0015180693008', ' | Time for epoch: 84.12s')\n",
      "('Epoch: 49/1001', '| Training accuracy: ', 1.0, '| Cost: 0.001996594714', ' | Time for epoch: 84.21s')\n",
      "('Epoch: 50/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00183449417818', ' | Time for epoch: 84.04s')\n",
      "('Epoch: 51/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00185335800052', ' | Time for epoch: 84.10s')\n",
      "('Epoch: 52/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00167071935721', ' | Time for epoch: 84.55s')\n",
      "('Epoch: 53/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00203122291714', ' | Time for epoch: 84.17s')\n",
      "('Epoch: 54/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00153983081691', ' | Time for epoch: 83.43s')\n",
      "('Epoch: 55/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00174747186247', ' | Time for epoch: 83.95s')\n",
      "('Epoch: 56/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00173333857674', ' | Time for epoch: 83.90s')\n",
      "('Epoch: 57/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00183188775554', ' | Time for epoch: 83.69s')\n",
      "('Epoch: 58/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00168418663088', ' | Time for epoch: 84.04s')\n",
      "('Epoch: 59/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00170482555404', ' | Time for epoch: 83.78s')\n",
      "('Epoch: 60/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00188786687795', ' | Time for epoch: 83.91s')\n",
      "('Epoch: 61/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00183406332508', ' | Time for epoch: 83.75s')\n",
      "('Epoch: 62/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00172065082006', ' | Time for epoch: 83.90s')\n",
      "('Epoch: 63/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00193955213763', ' | Time for epoch: 83.85s')\n",
      "('Epoch: 64/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00150395161472', ' | Time for epoch: 84.11s')\n",
      "('Epoch: 65/1001', '| Training accuracy: ', 1.0, '| Cost: 0.0014094702201', ' | Time for epoch: 84.35s')\n",
      "('Epoch: 66/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00162479199935', ' | Time for epoch: 84.59s')\n",
      "('Epoch: 67/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00160321791191', ' | Time for epoch: 84.63s')\n",
      "('Epoch: 68/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00170185125899', ' | Time for epoch: 84.23s')\n",
      "('Epoch: 69/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00171102012973', ' | Time for epoch: 84.17s')\n",
      "('Epoch: 70/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00161561532877', ' | Time for epoch: 84.36s')\n",
      "('Epoch: 71/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00129948928952', ' | Time for epoch: 83.88s')\n",
      "('Epoch: 72/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00155190075748', ' | Time for epoch: 84.47s')\n",
      "('Epoch: 73/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00154252909124', ' | Time for epoch: 83.91s')\n",
      "('Epoch: 74/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00163552421145', ' | Time for epoch: 84.65s')\n",
      "('Epoch: 75/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00142864976078', ' | Time for epoch: 84.18s')\n",
      "('Epoch: 76/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00972374435514', ' | Time for epoch: 84.81s')\n",
      "('Epoch: 77/1001', '| Training accuracy: ', 0.99609375, '| Cost: 0.0286626219749', ' | Time for epoch: 84.57s')\n",
      "('Epoch: 78/1001', '| Training accuracy: ', 1.0, '| Cost: 0.0103499488905', ' | Time for epoch: 84.41s')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch: 79/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00573846884072', ' | Time for epoch: 84.52s')\n",
      "('Epoch: 80/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00273771141656', ' | Time for epoch: 84.18s')\n",
      "('Epoch: 81/1001', '| Training accuracy: ', 1.0, '| Cost: 0.0025144002866', ' | Time for epoch: 83.66s')\n",
      "('Epoch: 82/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00228012329899', ' | Time for epoch: 83.87s')\n",
      "('Epoch: 83/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00181762920693', ' | Time for epoch: 83.68s')\n",
      "('Epoch: 84/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00192112580407', ' | Time for epoch: 84.20s')\n",
      "('Epoch: 85/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00189224944916', ' | Time for epoch: 84.33s')\n",
      "('Epoch: 86/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00173494569026', ' | Time for epoch: 83.56s')\n",
      "('Epoch: 87/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00169845891651', ' | Time for epoch: 84.15s')\n",
      "('Epoch: 88/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00161378714256', ' | Time for epoch: 84.11s')\n",
      "('Epoch: 89/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00200332445092', ' | Time for epoch: 83.93s')\n",
      "('Epoch: 90/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00159057078417', ' | Time for epoch: 84.21s')\n",
      "('Epoch: 91/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00110788212623', ' | Time for epoch: 84.31s')\n",
      "('Epoch: 92/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00156896747649', ' | Time for epoch: 84.47s')\n",
      "('Epoch: 93/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00138647807762', ' | Time for epoch: 84.25s')\n",
      "('Epoch: 94/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00143799267244', ' | Time for epoch: 83.98s')\n",
      "('Epoch: 95/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00162579480093', ' | Time for epoch: 83.94s')\n",
      "('Epoch: 96/1001', '| Training accuracy: ', 1.0, '| Cost: 0.0016761055449', ' | Time for epoch: 83.86s')\n",
      "('Epoch: 97/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00149048492312', ' | Time for epoch: 84.07s')\n",
      "('Epoch: 98/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00123124511447', ' | Time for epoch: 84.27s')\n",
      "('Epoch: 99/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00173925771378', ' | Time for epoch: 83.75s')\n",
      "('Epoch: 100/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00120171706658', ' | Time for epoch: 84.26s')\n",
      "('Epoch: 101/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00157757289708', ' | Time for epoch: 84.15s')\n",
      "('Epoch: 102/1001', '| Training accuracy: ', 1.0, '| Cost: 0.0014417412458', ' | Time for epoch: 84.20s')\n",
      "('Epoch: 103/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00145036680624', ' | Time for epoch: 83.92s')\n",
      "('Epoch: 104/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00130995921791', ' | Time for epoch: 84.28s')\n",
      "('Epoch: 105/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00181432499085', ' | Time for epoch: 84.31s')\n",
      "('Epoch: 106/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00123833422549', ' | Time for epoch: 84.48s')\n",
      "('Epoch: 107/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00120982981753', ' | Time for epoch: 84.15s')\n",
      "('Epoch: 108/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00179454335012', ' | Time for epoch: 83.57s')\n",
      "('Epoch: 109/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000989220570773', ' | Time for epoch: 83.62s')\n",
      "('Epoch: 110/1001', '| Training accuracy: ', 1.0, '| Cost: 0.0017350189155', ' | Time for epoch: 84.18s')\n",
      "('Epoch: 111/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00110957876313', ' | Time for epoch: 84.17s')\n",
      "('Epoch: 112/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00155104149599', ' | Time for epoch: 84.27s')\n",
      "('Epoch: 113/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00135939125903', ' | Time for epoch: 84.29s')\n",
      "('Epoch: 114/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00135097757448', ' | Time for epoch: 84.38s')\n",
      "('Epoch: 115/1001', '| Training accuracy: ', 1.0, '| Cost: 0.0010697459802', ' | Time for epoch: 84.42s')\n",
      "('Epoch: 116/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00133803428616', ' | Time for epoch: 84.09s')\n",
      "('Epoch: 117/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00168361468241', ' | Time for epoch: 84.36s')\n",
      "('Epoch: 118/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00118590821512', ' | Time for epoch: 83.77s')\n",
      "('Epoch: 119/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00137634703424', ' | Time for epoch: 84.43s')\n",
      "('Epoch: 120/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00104748655576', ' | Time for epoch: 84.37s')\n",
      "('Epoch: 121/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00157398043666', ' | Time for epoch: 84.14s')\n",
      "('Epoch: 122/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00115497480147', ' | Time for epoch: 84.01s')\n",
      "('Epoch: 123/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00128014746588', ' | Time for epoch: 83.98s')\n",
      "('Epoch: 124/1001', '| Training accuracy: ', 1.0, '| Cost: 0.0015074769035', ' | Time for epoch: 83.27s')\n",
      "('Epoch: 125/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000928999041207', ' | Time for epoch: 84.26s')\n",
      "('Epoch: 126/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00134244363289', ' | Time for epoch: 84.24s')\n",
      "('Epoch: 127/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00125719048083', ' | Time for epoch: 84.38s')\n",
      "('Epoch: 128/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00104014016688', ' | Time for epoch: 84.34s')\n",
      "('Epoch: 129/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00120129040442', ' | Time for epoch: 84.40s')\n",
      "('Epoch: 130/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00118648784701', ' | Time for epoch: 84.41s')\n",
      "('Epoch: 131/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00151098251808', ' | Time for epoch: 84.31s')\n",
      "('Epoch: 132/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00115666596685', ' | Time for epoch: 84.89s')\n",
      "('Epoch: 133/1001', '| Training accuracy: ', 1.0, '| Cost: 0.0013102464145', ' | Time for epoch: 83.68s')\n",
      "('Epoch: 134/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00106430938467', ' | Time for epoch: 83.46s')\n",
      "('Epoch: 135/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00121321016923', ' | Time for epoch: 83.60s')\n",
      "('Epoch: 136/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00108633993659', ' | Time for epoch: 83.54s')\n",
      "('Epoch: 137/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00147102272604', ' | Time for epoch: 83.41s')\n",
      "('Epoch: 138/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00118993152864', ' | Time for epoch: 83.76s')\n",
      "('Epoch: 139/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00104199268389', ' | Time for epoch: 84.01s')\n",
      "('Epoch: 140/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00106387981214', ' | Time for epoch: 83.81s')\n",
      "('Epoch: 141/1001', '| Training accuracy: ', 1.0, '| Cost: 0.0011815908365', ' | Time for epoch: 83.51s')\n",
      "('Epoch: 142/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00144446035847', ' | Time for epoch: 83.56s')\n",
      "('Epoch: 143/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00102663598955', ' | Time for epoch: 83.55s')\n",
      "('Epoch: 144/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00116154609714', ' | Time for epoch: 83.76s')\n",
      "('Epoch: 145/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00130421819631', ' | Time for epoch: 83.95s')\n",
      "('Epoch: 146/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00100824283436', ' | Time for epoch: 84.22s')\n",
      "('Epoch: 147/1001', '| Training accuracy: ', 1.0, '| Cost: 0.0010121477535', ' | Time for epoch: 83.93s')\n",
      "('Epoch: 148/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00127206963953', ' | Time for epoch: 84.00s')\n",
      "('Epoch: 149/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00140380766243', ' | Time for epoch: 84.26s')\n",
      "('Epoch: 150/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000748936843593', ' | Time for epoch: 83.89s')\n",
      "('Epoch: 151/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00123270018958', ' | Time for epoch: 84.17s')\n",
      "('Epoch: 152/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00095902645262', ' | Time for epoch: 83.98s')\n",
      "('Epoch: 153/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00136625010055', ' | Time for epoch: 83.79s')\n",
      "('Epoch: 154/1001', '| Training accuracy: ', 1.0, '| Cost: 0.0012296307832', ' | Time for epoch: 83.97s')\n",
      "('Epoch: 155/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000710950931534', ' | Time for epoch: 84.22s')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch: 156/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00109885446727', ' | Time for epoch: 84.71s')\n",
      "('Epoch: 157/1001', '| Training accuracy: ', 1.0, '| Cost: 0.001087379409', ' | Time for epoch: 84.30s')\n",
      "('Epoch: 158/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00136457092594', ' | Time for epoch: 84.49s')\n",
      "('Epoch: 159/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000814644095954', ' | Time for epoch: 84.23s')\n",
      "('Epoch: 160/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00107971543912', ' | Time for epoch: 84.15s')\n",
      "('Epoch: 161/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00106827961281', ' | Time for epoch: 84.43s')\n",
      "('Epoch: 162/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00105535041075', ' | Time for epoch: 84.38s')\n",
      "('Epoch: 163/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00133104703855', ' | Time for epoch: 84.54s')\n",
      "('Epoch: 164/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000903739826754', ' | Time for epoch: 84.43s')\n",
      "('Epoch: 165/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00104841298889', ' | Time for epoch: 84.32s')\n",
      "('Epoch: 166/1001', '| Training accuracy: ', 1.0, '| Cost: 0.0012016268447', ' | Time for epoch: 84.24s')\n",
      "('Epoch: 167/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000768971513025', ' | Time for epoch: 84.09s')\n",
      "('Epoch: 168/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00116428209003', ' | Time for epoch: 84.18s')\n",
      "('Epoch: 169/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00103044533171', ' | Time for epoch: 84.27s')\n",
      "('Epoch: 170/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00106467376463', ' | Time for epoch: 84.54s')\n",
      "('Epoch: 171/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00102344912011', ' | Time for epoch: 84.47s')\n",
      "('Epoch: 172/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00091341038933', ' | Time for epoch: 84.49s')\n",
      "('Epoch: 173/1001', '| Training accuracy: ', 1.0, '| Cost: 0.0014372545993', ' | Time for epoch: 84.63s')\n",
      "('Epoch: 174/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000609085080214', ' | Time for epoch: 84.91s')\n",
      "('Epoch: 175/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00128526682965', ' | Time for epoch: 84.86s')\n",
      "('Epoch: 176/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00100692478009', ' | Time for epoch: 84.69s')\n",
      "('Epoch: 177/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00101509608794', ' | Time for epoch: 84.65s')\n",
      "('Epoch: 178/1001', '| Training accuracy: ', 1.0, '| Cost: 0.0008521102136', ' | Time for epoch: 84.19s')\n",
      "('Epoch: 179/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00126924109645', ' | Time for epoch: 84.35s')\n",
      "('Epoch: 180/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00101174623705', ' | Time for epoch: 84.63s')\n",
      "('Epoch: 181/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000576205318794', ' | Time for epoch: 84.21s')\n",
      "('Epoch: 182/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00125576904975', ' | Time for epoch: 84.50s')\n",
      "('Epoch: 183/1001', '| Training accuracy: ', 1.0, '| Cost: 0.001007191604', ' | Time for epoch: 84.32s')\n",
      "('Epoch: 184/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00084440165665', ' | Time for epoch: 84.63s')\n",
      "('Epoch: 185/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00112303241622', ' | Time for epoch: 84.52s')\n",
      "('Epoch: 186/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000696079747286', ' | Time for epoch: 84.56s')\n",
      "('Epoch: 187/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000967078551184', ' | Time for epoch: 84.71s')\n",
      "('Epoch: 188/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00137044815347', ' | Time for epoch: 84.34s')\n",
      "('Epoch: 189/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000843385409098', ' | Time for epoch: 84.40s')\n",
      "('Epoch: 190/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000710702501237', ' | Time for epoch: 84.46s')\n",
      "('Epoch: 191/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000954128103331', ' | Time for epoch: 85.08s')\n",
      "('Epoch: 192/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000957336102147', ' | Time for epoch: 84.23s')\n",
      "('Epoch: 193/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000958568940405', ' | Time for epoch: 84.51s')\n",
      "('Epoch: 194/1001', '| Training accuracy: ', 1.0, '| Cost: 0.0010787966894', ' | Time for epoch: 84.32s')\n",
      "('Epoch: 195/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000939521822147', ' | Time for epoch: 84.66s')\n",
      "('Epoch: 196/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000937349861488', ' | Time for epoch: 84.65s')\n",
      "('Epoch: 197/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000933527189773', ' | Time for epoch: 84.42s')\n",
      "('Epoch: 198/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000808317447081', ' | Time for epoch: 84.31s')\n",
      "('Epoch: 199/1001', '| Training accuracy: ', 1.0, '| Cost: 0.0012071703095', ' | Time for epoch: 84.27s')\n",
      "('Epoch: 200/1001', '| Training accuracy: ', 1.0, '| Cost: 0.0317894890904', ' | Time for epoch: 84.26s')\n",
      "('Epoch: 201/1001', '| Training accuracy: ', 1.0, '| Cost: 0.011908557266', ' | Time for epoch: 84.56s')\n",
      "('Epoch: 202/1001', '| Training accuracy: ', 1.0, '| Cost: 0.004088757094', ' | Time for epoch: 83.96s')\n",
      "('Epoch: 203/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00401093903929', ' | Time for epoch: 84.31s')\n",
      "('Epoch: 204/1001', '| Training accuracy: ', 1.0, '| Cost: 0.001883945195', ' | Time for epoch: 84.14s')\n",
      "('Epoch: 205/1001', '| Training accuracy: ', 1.0, '| Cost: 0.0018873331137', ' | Time for epoch: 84.41s')\n",
      "('Epoch: 206/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00114560499787', ' | Time for epoch: 84.07s')\n",
      "('Epoch: 207/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00143079739064', ' | Time for epoch: 84.67s')\n",
      "('Epoch: 208/1001', '| Training accuracy: ', 0.99609375, '| Cost: 0.0130344275385', ' | Time for epoch: 84.48s')\n",
      "('Epoch: 209/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00730546377599', ' | Time for epoch: 84.43s')\n",
      "('Epoch: 210/1001', '| Training accuracy: ', 1.0, '| Cost: 0.003145809751', ' | Time for epoch: 84.42s')\n",
      "('Epoch: 211/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00164428097196', ' | Time for epoch: 84.52s')\n",
      "('Epoch: 212/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00168520933948', ' | Time for epoch: 84.37s')\n",
      "('Epoch: 213/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00131867139135', ' | Time for epoch: 84.43s')\n",
      "('Epoch: 214/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00112899648957', ' | Time for epoch: 84.46s')\n",
      "('Epoch: 215/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00106605701149', ' | Time for epoch: 84.46s')\n",
      "('Epoch: 216/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000998616451398', ' | Time for epoch: 84.51s')\n",
      "('Epoch: 217/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00164466549177', ' | Time for epoch: 84.44s')\n",
      "('Epoch: 218/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000967650150415', ' | Time for epoch: 84.45s')\n",
      "('Epoch: 219/1001', '| Training accuracy: ', 0.9921875, '| Cost: 0.00126267003361', ' | Time for epoch: 84.37s')\n",
      "('Epoch: 220/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00575566943735', ' | Time for epoch: 84.52s')\n",
      "('Epoch: 221/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00286828004755', ' | Time for epoch: 84.47s')\n",
      "('Epoch: 222/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00169573351741', ' | Time for epoch: 84.53s')\n",
      "('Epoch: 223/1001', '| Training accuracy: ', 1.0, '| Cost: 0.0011214883998', ' | Time for epoch: 84.48s')\n",
      "('Epoch: 224/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00138267886359', ' | Time for epoch: 84.47s')\n",
      "('Epoch: 225/1001', '| Training accuracy: ', 1.0, '| Cost: 0.0010554381879', ' | Time for epoch: 84.38s')\n",
      "('Epoch: 226/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000928554043639', ' | Time for epoch: 84.54s')\n",
      "('Epoch: 227/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00230704783462', ' | Time for epoch: 84.49s')\n",
      "('Epoch: 228/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00105480442289', ' | Time for epoch: 84.46s')\n",
      "('Epoch: 229/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00114272092469', ' | Time for epoch: 84.48s')\n",
      "('Epoch: 230/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000802567927167', ' | Time for epoch: 84.46s')\n",
      "('Epoch: 231/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00083659728989', ' | Time for epoch: 84.39s')\n",
      "('Epoch: 232/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000658011296764', ' | Time for epoch: 84.38s')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch: 233/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000757654779591', ' | Time for epoch: 84.45s')\n",
      "('Epoch: 234/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000773974694312', ' | Time for epoch: 84.41s')\n",
      "('Epoch: 235/1001', '| Training accuracy: ', 1.0, '| Cost: 0.0007357171271', ' | Time for epoch: 84.39s')\n",
      "('Epoch: 236/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00074039248284', ' | Time for epoch: 84.48s')\n",
      "('Epoch: 237/1001', '| Training accuracy: ', 1.0, '| Cost: 0.0007153491606', ' | Time for epoch: 84.49s')\n",
      "('Epoch: 238/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000845094851684', ' | Time for epoch: 84.51s')\n",
      "('Epoch: 239/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000571460463107', ' | Time for epoch: 84.46s')\n",
      "('Epoch: 240/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000830831355415', ' | Time for epoch: 84.46s')\n",
      "('Epoch: 241/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000563079898711', ' | Time for epoch: 84.45s')\n",
      "('Epoch: 242/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000720150826965', ' | Time for epoch: 84.35s')\n",
      "('Epoch: 243/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000825402501505', ' | Time for epoch: 84.41s')\n",
      "('Epoch: 244/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00069480255479', ' | Time for epoch: 84.48s')\n",
      "('Epoch: 245/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000543145695701', ' | Time for epoch: 84.51s')\n",
      "('Epoch: 246/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000832434277982', ' | Time for epoch: 84.47s')\n",
      "('Epoch: 247/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000531206664164', ' | Time for epoch: 84.53s')\n",
      "('Epoch: 248/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000661163940094', ' | Time for epoch: 84.47s')\n",
      "('Epoch: 249/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000657751574181', ' | Time for epoch: 84.39s')\n",
      "('Epoch: 250/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000682348618284', ' | Time for epoch: 84.42s')\n",
      "('Epoch: 251/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000649262452498', ' | Time for epoch: 84.43s')\n",
      "('Epoch: 252/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000655728450511', ' | Time for epoch: 84.48s')\n",
      "('Epoch: 253/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00064328458393', ' | Time for epoch: 84.42s')\n",
      "('Epoch: 254/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000671595335007', ' | Time for epoch: 84.59s')\n",
      "('Epoch: 255/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000652900896966', ' | Time for epoch: 84.48s')\n",
      "('Epoch: 256/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000799822446425', ' | Time for epoch: 84.43s')\n",
      "('Epoch: 257/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000632197770756', ' | Time for epoch: 84.41s')\n",
      "('Epoch: 258/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000631703529507', ' | Time for epoch: 84.49s')\n",
      "('Epoch: 259/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000617492478341', ' | Time for epoch: 84.52s')\n",
      "('Epoch: 260/1001', '| Training accuracy: ', 0.99609375, '| Cost: 0.000620022416115', ' | Time for epoch: 84.72s')\n",
      "('Epoch: 261/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000613349315245', ' | Time for epoch: 84.35s')\n",
      "('Epoch: 262/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000475491513498', ' | Time for epoch: 84.38s')\n",
      "('Epoch: 263/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000734527828172', ' | Time for epoch: 84.55s')\n",
      "('Epoch: 264/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000467282254249', ' | Time for epoch: 84.78s')\n",
      "('Epoch: 265/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000733653607313', ' | Time for epoch: 84.03s')\n",
      "('Epoch: 266/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000593564240262', ' | Time for epoch: 83.80s')\n",
      "('Epoch: 267/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00058991095284', ' | Time for epoch: 84.04s')\n",
      "('Epoch: 268/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000455905887065', ' | Time for epoch: 84.51s')\n",
      "('Epoch: 269/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000581328058615', ' | Time for epoch: 84.36s')\n",
      "('Epoch: 270/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000581400003284', ' | Time for epoch: 84.39s')\n",
      "('Epoch: 271/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000726097670849', ' | Time for epoch: 83.56s')\n",
      "('Epoch: 272/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000574650475755', ' | Time for epoch: 83.82s')\n",
      "('Epoch: 273/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000440421048552', ' | Time for epoch: 83.42s')\n",
      "('Epoch: 274/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000711477536242', ' | Time for epoch: 84.21s')\n",
      "('Epoch: 275/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000472675455967', ' | Time for epoch: 83.87s')\n",
      "('Epoch: 276/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000588736787904', ' | Time for epoch: 83.92s')\n",
      "('Epoch: 277/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00070779316593', ' | Time for epoch: 84.33s')\n",
      "('Epoch: 278/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000435513065895', ' | Time for epoch: 84.19s')\n",
      "('Epoch: 279/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000570695265196', ' | Time for epoch: 84.50s')\n",
      "('Epoch: 280/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000558864267077', ' | Time for epoch: 84.24s')\n",
      "('Epoch: 281/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00056015921291', ' | Time for epoch: 84.61s')\n",
      "('Epoch: 282/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00280309724621', ' | Time for epoch: 84.42s')\n",
      "('Epoch: 283/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000900645798538', ' | Time for epoch: 84.51s')\n",
      "('Epoch: 284/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00065724120941', ' | Time for epoch: 84.46s')\n",
      "('Epoch: 285/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000492036575451', ' | Time for epoch: 84.65s')\n",
      "('Epoch: 286/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000616636651102', ' | Time for epoch: 84.46s')\n",
      "('Epoch: 287/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000597881677095', ' | Time for epoch: 84.13s')\n",
      "('Epoch: 288/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000736033311114', ' | Time for epoch: 84.03s')\n",
      "('Epoch: 289/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000444276694907', ' | Time for epoch: 84.49s')\n",
      "('Epoch: 290/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000585309346206', ' | Time for epoch: 84.46s')\n",
      "('Epoch: 291/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000565553957131', ' | Time for epoch: 84.78s')\n",
      "('Epoch: 292/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00069714471465', ' | Time for epoch: 84.95s')\n",
      "('Epoch: 293/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00042032127385', ' | Time for epoch: 84.84s')\n",
      "('Epoch: 294/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000562051718589', ' | Time for epoch: 84.91s')\n",
      "('Epoch: 295/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000557880965061', ' | Time for epoch: 84.76s')\n",
      "('Epoch: 296/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000689324224368', ' | Time for epoch: 84.36s')\n",
      "('Epoch: 297/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000553494784981', ' | Time for epoch: 84.16s')\n",
      "('Epoch: 298/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000408883061027', ' | Time for epoch: 83.82s')\n",
      "('Epoch: 299/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000681215024088', ' | Time for epoch: 84.26s')\n",
      "('Epoch: 300/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000404753751354', ' | Time for epoch: 84.48s')\n",
      "('Epoch: 301/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000671978923492', ' | Time for epoch: 84.57s')\n",
      "('Epoch: 302/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00053324009059', ' | Time for epoch: 84.34s')\n",
      "('Epoch: 303/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000397823343519', ' | Time for epoch: 84.17s')\n",
      "('Epoch: 304/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000534775259439', ' | Time for epoch: 84.36s')\n",
      "('Epoch: 305/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000528776901774', ' | Time for epoch: 84.51s')\n",
      "('Epoch: 306/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000525556097273', ' | Time for epoch: 84.31s')\n",
      "('Epoch: 307/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000660132442135', ' | Time for epoch: 83.63s')\n",
      "('Epoch: 308/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000386276107747', ' | Time for epoch: 84.18s')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch: 309/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000662263424601', ' | Time for epoch: 84.15s')\n",
      "('Epoch: 310/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000384393613786', ' | Time for epoch: 84.55s')\n",
      "('Epoch: 311/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000518524437211', ' | Time for epoch: 84.24s')\n",
      "('Epoch: 312/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000655045907479', ' | Time for epoch: 84.70s')\n",
      "('Epoch: 313/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000373645714717', ' | Time for epoch: 84.65s')\n",
      "('Epoch: 314/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000653463415802', ' | Time for epoch: 84.34s')\n",
      "('Epoch: 315/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000378175638616', ' | Time for epoch: 85.03s')\n",
      "('Epoch: 316/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000505075149704', ' | Time for epoch: 84.79s')\n",
      "('Epoch: 317/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000510782236233', ' | Time for epoch: 84.90s')\n",
      "('Epoch: 318/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000502912385855', ' | Time for epoch: 84.37s')\n",
      "('Epoch: 319/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000642641272862', ' | Time for epoch: 83.82s')\n",
      "('Epoch: 320/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000503467395902', ' | Time for epoch: 84.07s')\n",
      "('Epoch: 321/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000366610765923', ' | Time for epoch: 84.06s')\n",
      "('Epoch: 322/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00063771015266', ' | Time for epoch: 84.22s')\n",
      "('Epoch: 323/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00035870357533', ' | Time for epoch: 84.12s')\n",
      "('Epoch: 324/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000496303196996', ' | Time for epoch: 83.73s')\n",
      "('Epoch: 325/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000635939941276', ' | Time for epoch: 84.28s')\n",
      "('Epoch: 326/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000495174375828', ' | Time for epoch: 84.21s')\n",
      "('Epoch: 327/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000493188330438', ' | Time for epoch: 84.37s')\n",
      "('Epoch: 328/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000350701622665', ' | Time for epoch: 84.26s')\n",
      "('Epoch: 329/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000488282646984', ' | Time for epoch: 84.42s')\n",
      "('Epoch: 330/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000628407287877', ' | Time for epoch: 84.65s')\n",
      "('Epoch: 331/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000348397996277', ' | Time for epoch: 84.66s')\n",
      "('Epoch: 332/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000487169570988', ' | Time for epoch: 84.65s')\n",
      "('Epoch: 333/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000619053840637', ' | Time for epoch: 84.92s')\n",
      "('Epoch: 334/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000487061624881', ' | Time for epoch: 84.33s')\n",
      "('Epoch: 335/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000342791812727', ' | Time for epoch: 83.68s')\n",
      "('Epoch: 336/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000484367250465', ' | Time for epoch: 84.35s')\n",
      "('Epoch: 337/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000478160160128', ' | Time for epoch: 83.91s')\n",
      "('Epoch: 338/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000476854300359', ' | Time for epoch: 84.47s')\n",
      "('Epoch: 339/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000616629957221', ' | Time for epoch: 84.21s')\n",
      "('Epoch: 340/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000332469149726', ' | Time for epoch: 84.40s')\n",
      "('Epoch: 341/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000475130684208', ' | Time for epoch: 84.53s')\n",
      "('Epoch: 342/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000472936051665', ' | Time for epoch: 84.62s')\n",
      "('Epoch: 343/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000617107201833', ' | Time for epoch: 84.05s')\n",
      "('Epoch: 344/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000465402816189', ' | Time for epoch: 84.75s')\n",
      "('Epoch: 345/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000331808609189', ' | Time for epoch: 84.30s')\n",
      "('Epoch: 346/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000464943586849', ' | Time for epoch: 84.66s')\n",
      "('Epoch: 347/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000469653488835', ' | Time for epoch: 84.58s')\n",
      "('Epoch: 348/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000603764143307', ' | Time for epoch: 84.29s')\n",
      "('Epoch: 349/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000325523957144', ' | Time for epoch: 84.64s')\n",
      "('Epoch: 350/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000466117169708', ' | Time for epoch: 84.28s')\n",
      "('Epoch: 351/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000602388754487', ' | Time for epoch: 84.62s')\n",
      "('Epoch: 352/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000468667712994', ' | Time for epoch: 84.32s')\n",
      "('Epoch: 353/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000318937294651', ' | Time for epoch: 84.69s')\n",
      "('Epoch: 354/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000463479635073', ' | Time for epoch: 84.35s')\n",
      "('Epoch: 355/1001', '| Training accuracy: ', 0.99609375, '| Cost: 0.000598139478825', ' | Time for epoch: 84.40s')\n",
      "('Epoch: 356/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000317085476127', ' | Time for epoch: 83.67s')\n",
      "('Epoch: 357/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000456094538094', ' | Time for epoch: 84.03s')\n",
      "('Epoch: 358/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000460085750092', ' | Time for epoch: 83.92s')\n",
      "('Epoch: 359/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000452661624877', ' | Time for epoch: 84.10s')\n",
      "('Epoch: 360/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000455060304375', ' | Time for epoch: 84.55s')\n",
      "('Epoch: 361/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000453476328403', ' | Time for epoch: 84.32s')\n",
      "('Epoch: 362/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000593329546973', ' | Time for epoch: 84.49s')\n",
      "('Epoch: 363/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000454275839729', ' | Time for epoch: 84.44s')\n",
      "('Epoch: 364/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000309817638481', ' | Time for epoch: 84.56s')\n",
      "('Epoch: 365/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000449018756626', ' | Time for epoch: 84.49s')\n",
      "('Epoch: 366/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000453916349215', ' | Time for epoch: 84.69s')\n",
      "('Epoch: 367/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00044745762716', ' | Time for epoch: 84.33s')\n",
      "('Epoch: 368/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000444772740593', ' | Time for epoch: 84.09s')\n",
      "('Epoch: 369/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000464686134364', ' | Time for epoch: 84.55s')\n",
      "('Epoch: 370/1001', '| Training accuracy: ', 0.99609375, '| Cost: 0.0145963197574', ' | Time for epoch: 84.60s')\n",
      "('Epoch: 371/1001', '| Training accuracy: ', 1.0, '| Cost: 0.0206469595432', ' | Time for epoch: 84.69s')\n",
      "('Epoch: 372/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00269024726003', ' | Time for epoch: 84.71s')\n",
      "('Epoch: 373/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00270730932243', ' | Time for epoch: 84.61s')\n",
      "('Epoch: 374/1001', '| Training accuracy: ', 1.0, '| Cost: 0.0119996564463', ' | Time for epoch: 83.95s')\n",
      "('Epoch: 375/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00326484278776', ' | Time for epoch: 83.86s')\n",
      "('Epoch: 376/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00159288174473', ' | Time for epoch: 83.87s')\n",
      "('Epoch: 377/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00355263892561', ' | Time for epoch: 84.19s')\n",
      "('Epoch: 378/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00179235299584', ' | Time for epoch: 84.31s')\n",
      "('Epoch: 379/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00123255094513', ' | Time for epoch: 84.42s')\n",
      "('Epoch: 380/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00248203519732', ' | Time for epoch: 84.36s')\n",
      "('Epoch: 381/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00253899791278', ' | Time for epoch: 84.51s')\n",
      "('Epoch: 382/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00122424948495', ' | Time for epoch: 84.26s')\n",
      "('Epoch: 383/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000789162353612', ' | Time for epoch: 84.44s')\n",
      "('Epoch: 384/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000745580415241', ' | Time for epoch: 84.67s')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch: 385/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000682670448441', ' | Time for epoch: 84.71s')\n",
      "('Epoch: 386/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000661216734443', ' | Time for epoch: 84.27s')\n",
      "('Epoch: 387/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000492773484439', ' | Time for epoch: 83.81s')\n",
      "('Epoch: 388/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000749489408918', ' | Time for epoch: 83.54s')\n",
      "('Epoch: 389/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000468289799755', ' | Time for epoch: 84.24s')\n",
      "('Epoch: 390/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000585480825976', ' | Time for epoch: 83.67s')\n",
      "('Epoch: 391/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000593692297116', ' | Time for epoch: 83.85s')\n",
      "('Epoch: 392/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000584737572353', ' | Time for epoch: 83.95s')\n",
      "('Epoch: 393/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00070504512405', ' | Time for epoch: 84.42s')\n",
      "('Epoch: 394/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000419010699261', ' | Time for epoch: 84.14s')\n",
      "('Epoch: 395/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000696551578585', ' | Time for epoch: 84.56s')\n",
      "('Epoch: 396/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000414886308135', ' | Time for epoch: 84.22s')\n",
      "('Epoch: 397/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000545204966329', ' | Time for epoch: 83.94s')\n",
      "('Epoch: 398/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000539697706699', ' | Time for epoch: 83.99s')\n",
      "('Epoch: 399/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000553234131075', ' | Time for epoch: 84.26s')\n",
      "('Epoch: 400/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000548947486095', ' | Time for epoch: 84.19s')\n",
      "('Epoch: 401/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000544259441085', ' | Time for epoch: 84.45s')\n",
      "('Epoch: 402/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000530803052243', ' | Time for epoch: 83.84s')\n",
      "('Epoch: 403/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000521317997482', ' | Time for epoch: 84.64s')\n",
      "('Epoch: 404/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000524693576153', ' | Time for epoch: 84.48s')\n",
      "('Epoch: 405/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000517432112247', ' | Time for epoch: 84.31s')\n",
      "('Epoch: 406/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000508519238792', ' | Time for epoch: 84.00s')\n",
      "('Epoch: 407/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000651280861348', ' | Time for epoch: 84.03s')\n",
      "('Epoch: 408/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000363516330253', ' | Time for epoch: 84.18s')\n",
      "('Epoch: 409/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00064335874049', ' | Time for epoch: 84.62s')\n",
      "('Epoch: 410/1001', '| Training accuracy: ', 1.0, '| Cost: 0.0003546520893', ' | Time for epoch: 84.51s')\n",
      "('Epoch: 411/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000640055397525', ' | Time for epoch: 84.64s')\n",
      "('Epoch: 412/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000352917326381', ' | Time for epoch: 84.30s')\n",
      "('Epoch: 413/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000493418076076', ' | Time for epoch: 84.63s')\n",
      "('Epoch: 414/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000639258651063', ' | Time for epoch: 84.37s')\n",
      "('Epoch: 415/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00048970564967', ' | Time for epoch: 84.59s')\n",
      "('Epoch: 416/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000347564986441', ' | Time for epoch: 84.18s')\n",
      "('Epoch: 417/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000626289402135', ' | Time for epoch: 84.39s')\n",
      "('Epoch: 418/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000339339661878', ' | Time for epoch: 84.53s')\n",
      "('Epoch: 419/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000471934123198', ' | Time for epoch: 84.67s')\n",
      "('Epoch: 420/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000623280182481', ' | Time for epoch: 84.59s')\n",
      "('Epoch: 421/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000335907534463', ' | Time for epoch: 84.38s')\n",
      "('Epoch: 422/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00060972920619', ' | Time for epoch: 84.01s')\n",
      "('Epoch: 423/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000470516592031', ' | Time for epoch: 84.27s')\n",
      "('Epoch: 424/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00032598990947', ' | Time for epoch: 84.39s')\n",
      "('Epoch: 425/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000604983535595', ' | Time for epoch: 84.38s')\n",
      "('Epoch: 426/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00046202208614', ' | Time for epoch: 83.84s')\n",
      "('Epoch: 427/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000318656035233', ' | Time for epoch: 84.02s')\n",
      "('Epoch: 428/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000462084863102', ' | Time for epoch: 84.03s')\n",
      "('Epoch: 429/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000456319394289', ' | Time for epoch: 84.13s')\n",
      "('Epoch: 430/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000455458648503', ' | Time for epoch: 83.64s')\n",
      "('Epoch: 431/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000450926396297', ' | Time for epoch: 84.26s')\n",
      "('Epoch: 432/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000456721521914', ' | Time for epoch: 83.64s')\n",
      "('Epoch: 433/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000450589956017', ' | Time for epoch: 84.59s')\n",
      "('Epoch: 434/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00044970610179', ' | Time for epoch: 84.23s')\n",
      "('Epoch: 435/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000596291269176', ' | Time for epoch: 84.61s')\n",
      "('Epoch: 436/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00030728513957', ' | Time for epoch: 84.24s')\n",
      "('Epoch: 437/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000587794813327', ' | Time for epoch: 84.06s')\n",
      "('Epoch: 438/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00030355504714', ' | Time for epoch: 83.24s')\n",
      "('Epoch: 439/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000443134689704', ' | Time for epoch: 84.29s')\n",
      "('Epoch: 440/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000590480922256', ' | Time for epoch: 84.05s')\n",
      "('Epoch: 441/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00126254057977', ' | Time for epoch: 83.28s')\n",
      "('Epoch: 442/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000696840987075', ' | Time for epoch: 83.98s')\n",
      "('Epoch: 443/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000363599538105', ' | Time for epoch: 83.39s')\n",
      "('Epoch: 444/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000473862979561', ' | Time for epoch: 83.83s')\n",
      "('Epoch: 445/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000473011954455', ' | Time for epoch: 84.13s')\n",
      "('Epoch: 446/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000464010459837', ' | Time for epoch: 84.10s')\n",
      "('Epoch: 447/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000601711391937', ' | Time for epoch: 83.94s')\n",
      "('Epoch: 448/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000311670213705', ' | Time for epoch: 83.83s')\n",
      "('Epoch: 449/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000455207366031', ' | Time for epoch: 84.16s')\n",
      "('Epoch: 450/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000448089645943', ' | Time for epoch: 84.29s')\n",
      "('Epoch: 451/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000442936114268', ' | Time for epoch: 84.11s')\n",
      "('Epoch: 452/1001', '| Training accuracy: ', 1.0, '| Cost: 0.0004412374401', ' | Time for epoch: 84.40s')\n",
      "('Epoch: 453/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000439467345132', ' | Time for epoch: 84.21s')\n",
      "('Epoch: 454/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000438387796748', ' | Time for epoch: 84.01s')\n",
      "('Epoch: 455/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000432477361755', ' | Time for epoch: 84.14s')\n",
      "('Epoch: 456/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000432986736996', ' | Time for epoch: 84.06s')\n",
      "('Epoch: 457/1001', '| Training accuracy: ', 0.99609375, '| Cost: 0.000578594801482', ' | Time for epoch: 84.39s')\n",
      "('Epoch: 458/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000286735099507', ' | Time for epoch: 84.41s')\n",
      "('Epoch: 459/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00057276134612', ' | Time for epoch: 84.52s')\n",
      "('Epoch: 460/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000282973749563', ' | Time for epoch: 84.64s')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Epoch: 461/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000430203072028', ' | Time for epoch: 84.59s')\n",
      "('Epoch: 462/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000424336612923', ' | Time for epoch: 84.58s')\n",
      "('Epoch: 463/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000566800765228', ' | Time for epoch: 84.33s')\n",
      "('Epoch: 464/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000424343685154', ' | Time for epoch: 84.36s')\n",
      "('Epoch: 465/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00027851035702', ' | Time for epoch: 84.20s')\n",
      "('Epoch: 466/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000420410709921', ' | Time for epoch: 84.06s')\n",
      "('Epoch: 467/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000416144728661', ' | Time for epoch: 84.39s')\n",
      "('Epoch: 468/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000418584677391', ' | Time for epoch: 83.96s')\n",
      "('Epoch: 469/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000416924391175', ' | Time for epoch: 83.62s')\n",
      "('Epoch: 470/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000416519527789', ' | Time for epoch: 83.76s')\n",
      "('Epoch: 471/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000417817092966', ' | Time for epoch: 83.96s')\n",
      "('Epoch: 472/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000410633219872', ' | Time for epoch: 83.91s')\n",
      "('Epoch: 473/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000555202481337', ' | Time for epoch: 83.74s')\n",
      "('Epoch: 474/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000410219567129', ' | Time for epoch: 84.17s')\n",
      "('Epoch: 475/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000267673720373', ' | Time for epoch: 84.28s')\n",
      "('Epoch: 476/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000408727966715', ' | Time for epoch: 84.43s')\n",
      "('Epoch: 477/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000407876126701', ' | Time for epoch: 84.16s')\n",
      "('Epoch: 478/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000412822177168', ' | Time for epoch: 84.46s')\n",
      "('Epoch: 479/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00040725179133', ' | Time for epoch: 84.38s')\n",
      "('Epoch: 480/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000405866128858', ' | Time for epoch: 84.56s')\n",
      "('Epoch: 481/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000550407625269', ' | Time for epoch: 84.48s')\n",
      "('Epoch: 482/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000258718413534', ' | Time for epoch: 84.11s')\n",
      "('Epoch: 483/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000402865291107', ' | Time for epoch: 84.37s')\n",
      "('Epoch: 484/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000402155681513', ' | Time for epoch: 84.11s')\n",
      "('Epoch: 485/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000402010657126', ' | Time for epoch: 84.00s')\n",
      "('Epoch: 486/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000399295095121', ' | Time for epoch: 83.92s')\n",
      "('Epoch: 487/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000400492717745', ' | Time for epoch: 83.90s')\n",
      "('Epoch: 488/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000403525016736', ' | Time for epoch: 84.44s')\n",
      "('Epoch: 489/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000401919620344', ' | Time for epoch: 84.00s')\n",
      "('Epoch: 490/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000546644092537', ' | Time for epoch: 84.36s')\n",
      "('Epoch: 491/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000397779542254', ' | Time for epoch: 84.40s')\n",
      "('Epoch: 492/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000400250311941', ' | Time for epoch: 84.19s')\n",
      "('Epoch: 493/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000395956361899', ' | Time for epoch: 84.60s')\n",
      "('Epoch: 494/1001', '| Training accuracy: ', 1.0, '| Cost: 0.00024954235414', ' | Time for epoch: 84.20s')\n",
      "('Epoch: 495/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000396327726776', ' | Time for epoch: 84.63s')\n",
      "('Epoch: 496/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000392143323552', ' | Time for epoch: 86.29s')\n",
      "('Epoch: 497/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000391727720853', ' | Time for epoch: 84.32s')\n",
      "('Epoch: 498/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000393680878915', ' | Time for epoch: 84.11s')\n",
      "('Epoch: 499/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000392362795537', ' | Time for epoch: 84.30s')\n",
      "('Epoch: 500/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000536091683898', ' | Time for epoch: 84.28s')\n",
      "('Epoch: 501/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000245917093707', ' | Time for epoch: 83.60s')\n",
      "('Epoch: 502/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000533324317075', ' | Time for epoch: 84.18s')\n",
      "('Epoch: 503/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000244085022132', ' | Time for epoch: 83.99s')\n",
      "('Epoch: 504/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000388125685276', ' | Time for epoch: 85.56s')\n",
      "('Epoch: 505/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000385554740205', ' | Time for epoch: 86.36s')\n",
      "('Epoch: 506/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000384606129956', ' | Time for epoch: 84.91s')\n",
      "('Epoch: 507/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000531024066731', ' | Time for epoch: 84.97s')\n",
      "('Epoch: 508/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000383396167308', ' | Time for epoch: 84.33s')\n",
      "('Epoch: 509/1001', '| Training accuracy: ', 1.0, '| Cost: 0.000240624402068', ' | Time for epoch: 84.20s')\n"
     ]
    }
   ],
   "source": [
    "optimize(step_momentum, 1001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.993990361691\n"
     ]
    }
   ],
   "source": [
    "# check the test dataset performance\n",
    "acc_list = []\n",
    "for ii in range(mnist_data.test.num_examples//batch_size):\n",
    "    batch = mnist_data.test.next_batch(batch_size)\n",
    "    imgs = batch[0].reshape((-1, 28, 28, 1))\n",
    "    labs = batch[1]\n",
    "\n",
    "    dict_input = {inputs:imgs, targets:labs, \n",
    "                  train_flag: False, \n",
    "                  shortcut_flag: False,\n",
    "                  input_shortcut: np.zeros([batch_size, 2])}\n",
    "\n",
    "    acc = session.run(accuracy, feed_dict=dict_input)\n",
    "    acc_list.append(acc)\n",
    "print(\"Test accuracy: {}\".format(np.mean(acc_list)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_temp_all(feature, label, feature_t, label_t, \n",
    "                    name=None):\n",
    "    pylab.figure()\n",
    "    color_list = ['k', 'grey', 'lightgray', 'lightcoral', 'maroon',\n",
    "                 'mistyrose', 'coral', 'orange','darkgoldenrod',\n",
    "                 'olive', 'yellow', 'm', 'g', 'c','cadetblue',\n",
    "                 'dodgerblue','slateblue','violet','darkred','r']\n",
    "    points_random = list()\n",
    "    points_t = list()\n",
    "    for i in range(10):\n",
    "        points_random.append(feature[label==i])\n",
    "        points_t.append(feature_t[label_t==i])\n",
    "\n",
    "    for i in range(10):\n",
    "        pylab.scatter(points_random[i][:,0], points_random[i][:,1],\n",
    "                      c=color_list[i], marker='o')\n",
    "        pylab.scatter(points_t[i][:,0], points_t[i][:,1], \n",
    "                      c=color_list[i+10], marker='o')\n",
    "    pylab.xticks(fontsize=17)\n",
    "    pylab.yticks(fontsize=17)\n",
    "    if name==None:\n",
    "        pylab.show()\n",
    "    else:\n",
    "        pylab.savefig(name)\n",
    "        \n",
    "def random_points_10(start_x, end_x, start_y, end_y, size, random_state):\n",
    "\tnp.random.seed(random_state)\n",
    "\tx1 = np.random.uniform(start_x, end_x, size)\n",
    "\tx2 = np.random.uniform(start_y, end_y, size)\n",
    "\tfeature =  np.vstack([x1,x2]).transpose()\n",
    "\tlabel = np.random.choice(10,size)\n",
    "\treturn feature, label\n",
    "\n",
    "def get_svm(feature, label):\n",
    "    from sklearn.svm import LinearSVC\n",
    "    clf = LinearSVC(multi_class='ovr')\n",
    "    clf.fit(feature, label)\n",
    "    return clf\n",
    "\n",
    "def plot_blobs(feature_t, label_t, \n",
    "                    name=None):\n",
    "    pylab.figure()\n",
    "\n",
    "    color_list = ['k', 'grey', 'lightgray', 'lightcoral', 'maroon',\n",
    "                 'mistyrose', 'coral', 'orange','darkgoldenrod',\n",
    "                 'olive', 'yellow', 'm', 'g', 'c','cadetblue',\n",
    "                 'dodgerblue','slateblue','violet','darkred','r']\n",
    "    points_t = list()\n",
    "    for i in range(10):\n",
    "        points_t.append(feature_t[label_t==i])\n",
    "\n",
    "    for i in range(10):\n",
    "        try:\n",
    "            pylab.scatter(points_t[i][:,0], points_t[i][:,1], \n",
    "                          c=color_list[i], marker='.')\n",
    "        except:\n",
    "            print i\n",
    "    pylab.xticks(fontsize=17)\n",
    "    pylab.yticks(fontsize=17)\n",
    "    if name==None:\n",
    "        pylab.show()\n",
    "    else:\n",
    "        pylab.savefig(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_t = []\n",
    "label_t = []\n",
    "\n",
    "for ii in range(mnist_data.train.num_examples//batch_size):\n",
    "    batch = mnist_data.train.next_batch(batch_size)\n",
    "    imgs = batch[0].reshape((-1, 28, 28, 1))\n",
    "    labs = batch[1]\n",
    "    label_t.append(labs)\n",
    "    \n",
    "    dict_input = {inputs:imgs, targets:labs, \n",
    "                  train_flag: False, \n",
    "                  shortcut_flag: False,\n",
    "                  input_shortcut: np.zeros([batch_size, 2])}\n",
    "\n",
    "    feature_t.append(session.run(feature_transform, feed_dict=dict_input))\n",
    "\n",
    "label_t = np.concatenate(label_t, 0)\n",
    "label_t = np.argmax(label_t, 1)\n",
    "feature_t = np.concatenate(feature_t, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEECAYAAAA/L9PCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nOIwxxhRhw2GMMaaIX998L6XaewK/AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x3ed02d90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_blobs(feature_t, label_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# transformed space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_random, label_random = random_points_10(-10,\n",
    "    140,-10,140, 30000,\n",
    "    random_state=100)\n",
    "label_random = to_categorical(label_random, 10)\n",
    "pre_label_nn= session.run(\n",
    "    pred_y_true,\n",
    "    feed_dict={inputs:imgs, \n",
    "               targets:label_random,\n",
    "               train_flag: False, \n",
    "               shortcut_flag: True,\n",
    "               input_shortcut: feature_random})\n",
    "\n",
    "clf = get_svm(feature_t, label_t)\n",
    "pre_label_svm = clf.predict(feature_random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_temp_all(feature_random, pre_label_nn,feature_t, label_t)\n",
    "plot_temp_all(feature_random, pre_label_svm,feature_t, label_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_temp_all(feature_random, pre_label_nn,feature_t, label_t, '../result/mnist_3_class_densenet/nn_transformed.png')\n",
    "plot_temp_all(feature_random, pre_label_svm,feature_t, label_t, '../result/mnist_3_class_densenet/svm_transformed.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
