{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import tflearn\n",
    "from utils import *\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]='1'\n",
    "mnist_data = input_data.read_data_sets(\"MNIST_data\", one_hot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inputs = tf.placeholder(tf.float32, [None, 28, 28, 1], name='inputs')\n",
    "targets = tf.placeholder(tf.float32, [None, 3], name='targets')\n",
    "input_shortcut = tf.placeholder(tf.float32, [None, 2], name='input_shortcut')\n",
    "train_flag = tf.placeholder(tf.bool, name='training')\n",
    "\n",
    "\n",
    "net = tflearn.conv_2d(inputs, 64, 3, activation='relu', bias=False)\n",
    "# Residual blocks\n",
    "net = tflearn.residual_bottleneck(net, 3, 16, 64)\n",
    "net = tflearn.residual_bottleneck(net, 1, 32, 128, downsample=True)\n",
    "net = tflearn.residual_bottleneck(net, 2, 32, 128)\n",
    "net = tflearn.residual_bottleneck(net, 1, 64, 256, downsample=True)\n",
    "net = tflearn.residual_bottleneck(net, 2, 64, 256)\n",
    "net = tflearn.batch_normalization(net)\n",
    "net = tflearn.activation(net, 'relu')\n",
    "net = tflearn.global_avg_pool(net)\n",
    "\n",
    "net = tflearn.fully_connected(net, 200, activation='relu')\n",
    "feature_transform = tflearn.fully_connected(net, 2, activation='relu')\n",
    "output = dense_custom(tf.cond(train_flag, lambda: feature_transform,\n",
    "                              lambda: input_shortcut),\n",
    "                      2, 3, activation=None)\n",
    "\n",
    "#This part is for computing the accuracy of this model\n",
    "pred_y = tf.nn.softmax(output)\n",
    "pred_y_true = tf.argmax(pred_y, 1)\n",
    "y_true = tf.argmax(targets, 1)\n",
    "correct_prediction = tf.equal(pred_y_true, y_true)\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "\n",
    "# loss function and optimizer\n",
    "cost = tf.reduce_mean((tf.nn.softmax_cross_entropy_with_logits(logits=output, labels=targets)))\n",
    "\n",
    "step_adam = tf.train.AdamOptimizer(1e-4).minimize(cost)\n",
    "step_momentum = tf.train.MomentumOptimizer(0.001, 0.9).minimize(cost)\n",
    "step_gd = tf.train.GradientDescentOptimizer(0.0001).minimize(cost)\n",
    "\n",
    "all_variables = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES)\n",
    "last_layer_variables = filter(lambda x: 'Variable' in x.name, all_variables)\n",
    "previous_layer_variables = filter(lambda x: 'Variable' not in x.name, all_variables)\n",
    "\n",
    "step_sgd_previous_layer = tf.train.GradientDescentOptimizer(0.0001).minimize(cost,\n",
    "                        var_list = previous_layer_variables)\n",
    "\n",
    "optimizer_sgd_last_layer = tf.train.GradientDescentOptimizer(1e-4)\n",
    "step_sgd_last_layer = optimizer_sgd_last_layer.minimize(cost,\n",
    "                        var_list = last_layer_variables)\n",
    "optimizer_m_last_layer = tf.train.MomentumOptimizer(1e-4, 0.9)\n",
    "step_m_last_layer = optimizer_m_last_layer.minimize(cost,\n",
    "                        var_list = last_layer_variables)\n",
    "\n",
    "\n",
    "# optimizer = tf.train.MomentumOptimizer(0.0001, 0.9).minimize(cost)\n",
    "saver = tf.train.Saver(tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES))\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.log_device_placement=False\n",
    "config.allow_soft_placement=True\n",
    "config.gpu_options.allow_growth=True\n",
    "session = tf.Session(config=config)\n",
    "session.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_3_class(imgs, labs):\n",
    "    label = np.argmax(labs,1)\n",
    "    index_0 = np.where(label==0)[0]\n",
    "    index_1 = np.where(label==1)[0]\n",
    "    index_2 = np.where(label==2)[0]\n",
    "    index = list(index_0)+list(index_1)+list(index_2)\n",
    "    images = imgs[index]\n",
    "    label = label[index]\n",
    "    label = to_categorical(label, 3)\n",
    "    return images, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batch_size = 4096\n",
    "def optmizer(optimizer_step, epochs):\n",
    "\n",
    "    for i in (range(epochs)):\n",
    "        epoch_loss = []\n",
    "        start_epoch = time.time()\n",
    "        for ii in range(mnist_data.train.num_examples//batch_size):\n",
    "            batch = mnist_data.train.next_batch(batch_size)\n",
    "            imgs = batch[0].reshape((-1, 28, 28, 1))\n",
    "            labs = batch[1]\n",
    "            imgs, labs = get_3_class(imgs, labs)\n",
    "\n",
    "            dict_input = {inputs:imgs, targets:labs, train_flag: True, \n",
    "                         input_shortcut: np.zeros([batch_size, 2])}\n",
    "\n",
    "            c, _ = session.run([cost, optimizer_step], feed_dict=dict_input)\n",
    "            epoch_loss.append(c)\n",
    "        print(\"Epoch: {}/{}\".format(i+1, epochs), \"| Training accuracy: \", session.run(accuracy, feed_dict=dict_input), \n",
    "              \"| Cost: {}\".format(np.mean(epoch_loss)), \" | Time for epoch: {:.2f}s\".format(time.time() - start_epoch))\n",
    "        if i%100==0:\n",
    "            saver.save(session,'../model/mnist_resnet_3_class_mom_{}.ckpt'.format(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optmizer(step_momentum, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def plot_temp_all_3(feature, label, feature_t, label_t, \n",
    "                    name=None):\n",
    "    pylab.figure()\n",
    "    red = feature[label == 0]\n",
    "    blue = feature[label == 1]\n",
    "    c = feature[label == 2]\n",
    "    green = feature_t[label_t == 0]\n",
    "    black = feature_t[label_t == 1]\n",
    "    yellow = feature_t[label_t == 2]\n",
    "\n",
    "    pylab.plot(red[:, 0], red[:, 1], 'r.')\n",
    "    pylab.plot(blue[:, 0], blue[:, 1], 'b.')\n",
    "    pylab.plot(c[:, 0], c[:,1], 'c.')\n",
    "    pylab.plot(green[:, 0], green[:, 1], 'g.')\n",
    "    pylab.plot(black[:, 0], black[:, 1], 'k.')\n",
    "    pylab.plot(yellow[:, 0], yellow[:, 1], 'y.')\n",
    "    pylab.xticks(fontsize=17)\n",
    "    pylab.yticks(fontsize=17)\n",
    "    if name==None:\n",
    "        pylab.show()\n",
    "    else:\n",
    "        pylab.savefig(name)\n",
    "\n",
    "\n",
    "def random_points_3(start_x, end_x, start_y, end_y, size, random_state):\n",
    "\tnp.random.seed(random_state)\n",
    "\tx1 = np.random.uniform(start_x, end_x, size)\n",
    "\tx2 = np.random.uniform(start_y, end_y, size)\n",
    "\tfeature =  np.vstack([x1,x2]).transpose()\n",
    "\tlabel = np.random.choice(3,size)\n",
    "\treturn feature, label\n",
    "\n",
    "def get_svm(feature, label):\n",
    "    from sklearn.svm import LinearSVC\n",
    "    clf = LinearSVC(multi_class='ovr')\n",
    "    clf.fit(feature, label)\n",
    "    return clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# def get_transform_feature():\n",
    "feature_t = session.run(feature_transform, \n",
    "            feed_dict={inputs:feature, targets:label_hot, \n",
    "                       train_flag: True, \n",
    "                       input_shortcut: np.zeros([100, 2])})\n",
    "label_t = label\n",
    "feature_t = np.array(feature_t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plot_blobs_3(feature_t, label_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Original space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_random, label_random = random_points_3(-20,\n",
    "    100,-20,100, 30000,\n",
    "    random_state=100)\n",
    "label_random = to_categorical(label_random, 3)\n",
    "pre_label_nn= session.run(\n",
    "    pred_y_true,\n",
    "    feed_dict={inputs:feature_random, \n",
    "               targets:label_random,\n",
    "               train_flag: True, \n",
    "               input_shortcut: feature_random})\n",
    "\n",
    "clf = get_svm(feature, label)\n",
    "pre_label_svm = clf.predict(feature_random)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_temp_all_3(feature_random, pre_label_nn,feature, label_t)\n",
    "plot_temp_all_3(feature_random, pre_label_svm,feature, label_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_temp_all_3(feature_random, pre_label_nn,feature, label_t , '../result/adam_3_class/nn_original.png')\n",
    "plot_temp_all_3(feature_random, pre_label_svm,feature, label_t, '../result/adam_3_class/svm_original.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# transformed space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "feature_random, label_random = random_points_3(0,\n",
    "    100,0,300, 30000,\n",
    "    random_state=100)\n",
    "label_random = to_categorical(label_random, 3)\n",
    "pre_label_nn= session.run(\n",
    "    pred_y_true,\n",
    "    feed_dict={inputs:feature_random, \n",
    "               targets:label_random,\n",
    "               train_flag: False, \n",
    "               input_shortcut: feature_random})\n",
    "\n",
    "clf = get_svm(feature_t, label_t)\n",
    "pre_label_svm = clf.predict(feature_random)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_temp_all_3(feature_random, pre_label_nn,feature_t, label_t)\n",
    "plot_temp_all_3(feature_random, pre_label_svm,feature_t, label_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plot_temp_all_3(feature_random, pre_label_nn,feature_t, label_t, '../result/adam_3_class/nn_transformed.png')\n",
    "plot_temp_all_3(feature_random, pre_label_svm,feature_t, label_t, '../result/adam_3_class/svm_transformed.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
